---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Wenbo Jiang is currently an Associate Professor in the School of Computer Science and Engineering (School of Cyberspace Security) at the University of Electronic Science and Technology of China, in the group of Prof. Hongwei Li (IEEE Fellow). Dr. Jiang was awarded for the National Postdoctoral Innovative Talent Support Program in 2023, and obtained youth program of the National Natural Science Foundation of China in 2024. As the first/corresponding author, he has published many papers in major conferences/journals, including USENIX Security、CCS、CVPR、AAAI、ICML、TDSC、TIFS, etc. His research interests includes AI security and data security.


Education
======
2013-2023: Bachelor and PhD degree in Cyber Security, University of Electronic Science and Technology of China (supervised by Prof. Hongwei Li).<br>
2021-2022: Visiting PhD in Cyber Security, Nanyang Technological University (supervised by Prof. Tianwei Zhang).<br>


Academic service
======
+ Area Chair: ICASSP 2026, ICLR 2026, IJCNN 2025, BMVC 2025. <br>
+ Guest editor: A special issue of Electronics (Security and Privacy for AI)  https://www.mdpi.com/journal/electronics/special_issues/F996X09SVU. <br>
+ Workshop Chair: DLNN 2025 (AI Security and Privacy: Building Robust, Trustworthy, and Explainable AI Systems). <br>
+ Session Chair: ICC 2019.<br>
+ PC/Reviewer for conference: AAAI 2025, NIPS 2025, KDD 2025, ICCV 2025, CLOM 2025, CVPR 2025, ICLR 2025, etc.<br>
+ Reviewer for journals: IEEE TIFS, IEEE TDSC, IEEE TCSVT, IEEE IoTJ, IEEE TNNLS, IEEE TAI, IEEE TVT, ACM TOIT, etc.<br>

News
======
+ 2025.12: One paper accepted by USENIX Security Symposium 2026 (CCF-A). <br>
+ 2025.11: Three papers accepted by AAAI 2026 (CCF-A). <br>
+ 2025.10: One paper accepted by NeurIPS 2025 (CCF-A). <br>
+ 2025.10: Our CCS2025 papaer "DivTrackee versus DynTracker: Promoting Diversity in Anti-Facial Recognition against Dynamic FR Strategy" has been awarded the **Distinguished Paper Award!** <br>
+ 2025.08: Invited as an Area Chair for ICLR 2026.<br>
+ 2025.08: One paper accepted by TDSC (CCF-A). <br>
+ 2025.08: One paper accepted by TIFS (CCF-A). <br>
+ 2025.08: One paper accepted by EMNLP 2025 (CCF-B). <br>
+ 2025.07: One paper accepted by ECAI 2025 (CCF-B). <br>
+ 2025.07: Invited as a Program Committee for AAAI 2026.<br>
+ 2025.05: Invited as an Area Chair for BMVC 2025.<br>
+ 2025.05: Two paper accepted by ICML 2025 (CCF-A). <br>
+ 2025.03: One paper accepted by CCS 2025 (CCF-A).<br>

Selected publications
======
+ Qiyang Song, Qihang Zhou, Xiaoqi Jia, Zhenyu Song, **Wenbo Jiang**, Heqing Huang, Yong Liu, Dan Meng. vCause: Efficient and Verifiable Causality Analysis for Cloud-based Endpoint Auditing. The 35th USENIX Security Symposium, 2026. <br>
+	Shuai Yuan, Xingshuo Han, Hongwei Li, Guowen Xu, **Wenbo Jiang**, Tao Ni, Qingchuan Zhao, Yuguang Fang. The Fluorescent Veil: A Stealthy and Effective Physical Adversarial Patch Against Traffic Sign Recognition. The Thirty-Ninth Annual Conference on Neural Information Processing Systems, 2025. <br>
+	Zihan Wang, Rui Zhang, Yu Liu, Wenshu Fan, **Wenbo Jiang**, Qingchuan Zhao, Hongwei Li, Guowen Xu. MPMA: Preference Manipulation Attack Against Model Context Protocol. The Fortieth AAAI Conference on Artificial Intelligence (AAAI), 2026. <br>
+	Zihan Wang, Rui Zhang, Hongwei Li, Wenshu Fan, **Wenbo Jiang**, Qingchuan Zhao, Guowen Xu. ConfGuard: A Simple and Effective Backdoor Detection for Large Language Models. The Fortieth AAAI Conference on Artificial Intelligence (AAAI), 2026. <br>
+	Hanxiao Chen, Hongwei Li, Meng Hao, Pengzhi Xing, Jia Hu, **Wenbo Jiang**, Tianwei Zhang, and Guowen Xu. Conan: Secure and Reliable Machine Learning Inference against Malicious Service Providers. IEEE Transactions on Information Forensics and Security (TIFS), 2025. <br>
+	Xin Liu, Qiyang Song, Qihang Zhou, Haichao Du, Shaowen Xu, Wenbo Jiang, Weijuan Zhang, Xiaoqi Jia. Focusing on Language: Revealing and Exploiting Language Attention Heads in Multilingual Large Language Models. The Fortieth AAAI Conference on Artificial Intelligence (AAAI), 2026. <br>
+	Kunlan Xiang, Haomiao Yang, Meng Hao, Shaofeng Li, Haoxin Wang, Zikang Ding, **Wenbo Jiang**, Tianwei Zhang. The Gradient Puppeteer: Adversarial Domination in Gradient Leakage Attacks through Model Poisoning. IEEE Transactions on Information Forensics and Security (TIFS), 2025. <br>
+	**Wenbo Jiang**, Hongwei Li, Jiaming He, Rui Zhang, Guowen Xu, Tianwei Zhang, Rongxing Lu. I2I Backdoor: Backdoor Attacks against Image-to-Image Tasks. IEEE Transactions on Dependable and Secure Computing(TDSC), 2025. <br>
+ Rui Zhang, Yun Shen, Hongwei Li, **Wenbo Jiang**, Hanxiao Chen, Yuan Zhang, Guowen Xu, Yang Zhang. The Ripple Effect: On Unforeseen Complications of Backdoor Attacks. International Conference on Machine Learning (ICML), 2025.<br>
+ Guanyu Hou, Jiaming He, Yinhang Zhou, Yitong Qiao, Ji Guo, Rui Zhang, **Wenbo Jiang**, “Evaluating Robustness of Large Audio Language Models to Audio Injection: An Empirical Study”, EMNLP 2025 <br>
+ Shuai Yuan, Hongwei Li, Rui Zhang, Hangcheng Cao, **Wenbo Jiang**, Tao Ni, Wenshu Fan, Qingchuan Zhao, Guowen Xu. Omni-Angle Assault: An Invisible and Powerful Physical Adversarial Attack on Face Recognition. International Conference on Machine Learning (ICML), 2025.<br>
+ Wenshu Fan, Minxing Zhang, Hongwei Li, **Wenbo Jiang***, Hanxiao Chen, Xiangyu Yue, Michael Backes, Xiao Zhang, "DivTrackee versus DynTracker: Promoting Diversity in Anti-Facial Recognition against Dynamic FR Strategy", in Proceedings of ACM SIGSAC Conference on Computer and Communications Security (CCS) (Distinguished Paper Award), 2025.<br>
+ **Wenbo Jiang**, Hongwei Li, Guowen Xu, Hao Ren, Haomiao Yang, Tianwei Zhang, Shui Yu, "Rethinking the Design of Backdoor Triggers and Adversarial Perturbations: A Color Space Perspective" in IEEE Transactions on Dependable and Secure Computing, DOI: 10.1109/TDSC.2024.3521942.<br>
+ Jiaming He, **Wenbo Jiang***, Guanyu Hou, Wenshu Fan, Rui Zhang and Hongwei Li. " Watch Out for Your Guidance on Generation! Exploring Conditional Backdoor Attacks against Large Language Models." Proceedings of the AAAI 2025.<br>
+ **Wenbo Jiang**, H. Li, G. Xu, T. Zhang, "Color backdoor: A robust poisoning attack in color space" in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023, pp. 8133-8142.<br>
+ **Wenbo Jiang**, H. Li, G. Xu, T. Zhang and R. Lu, "A Comprehensive Defense Framework Against Model Extraction Attacks," in IEEE Transactions on Dependable and Secure Computing, vol. 21, no. 2, pp. 685-700, March-April 2024, doi: 10.1109/TDSC.2023.3261327.<br>
+ W. Fan, H. Li, **Wenbo Jiang***, M. Hao, S. Yu and X. Zhang, "Stealthy Targeted Backdoor Attacks Against Image Captioning," in IEEE Transactions on Information Forensics and Security, vol. 19, pp. 5655-5667, 2024, doi: 10.1109/TIFS.2024.3402179.<br>
+ R. Zhang, H. Li, R. Wen, **Wenbo Jiang**, Y. Zhang, M. Backes, Y. Shen and Y. Zhang, "Instruction backdoor attacks against customized {LLMs}," In 33rd USENIX Security Symposium (USENIX Security 24) (pp. 1849-1866).<br>
+ **Wenbo Jiang**, T. Zhang, H. Qiu, H. Li and G. Xu, "Incremental Learning, Incremental Backdoor Threats," in IEEE Transactions on Dependable and Secure Computing, vol. 21, no. 2, pp. 559-572, March-April 2024, doi: 10.1109/TDSC.2022.3201234.<br>

[Google scholar](https://scholar.google.com/citations?user=OjHzvJkAAAAJ)

